# D:\disease_prediction_project\check_data_preview.py
import pandas as pd
from pathlib import Path
from colorama import Fore, Style, init

# Initialize colorama
init(autoreset=True)

# --- Configuration ---
# File generated by data_merger.py, used for training
TRAINING_DATA_PATH = Path("data/merged_comprehensive_data.csv")
# Source file for knowledge base generator (expected wide format)
KB_SOURCE_DATA_PATH = Path("data/DiseaseAndSymptoms.csv")

def preview_dataframe(df_path: Path, expected_cols: set = None, description: str = "Data File"):
    """Loads, previews, and performs basic checks on a DataFrame."""
    print(f"\n{Fore.CYAN}{'='*20} Previewing: {description} ({df_path.name}) {'='*20}")

    if not df_path.exists():
        print(f"{Fore.RED}‚ùå File not found: {df_path}")
        print(f"{Fore.CYAN}{'='* (44 + len(description) + len(df_path.name))}")
        return False # Indicate failure

    try:
        df = pd.read_csv(df_path)
        print(f"{Fore.GREEN}‚úÖ File loaded successfully ‚Äî {len(df)} rows found.")

        print(f"\n{Fore.BLUE}üîπ Sample of first 5 rows:")
        # Use display options for better formatting if wide
        with pd.option_context('display.max_rows', 5, 'display.max_columns', 10, 'display.width', 120):
             print(df.head(5))

        print(f"\n{Fore.BLUE}üîπ Columns present:")
        print(f"   {list(df.columns)}")

        if expected_cols:
            if expected_cols.issubset(df.columns):
                print(f"{Fore.GREEN}‚úÖ Contains expected columns: {expected_cols}.")
            else:
                missing = expected_cols - set(df.columns)
                print(f"{Fore.RED}‚ùå Missing expected columns: {missing}.")
                return False # Indicate failure if expected columns are missing

        # Show top diseases if 'disease' column exists (after potential lowercase conversion)
        disease_col_found = None
        for col in df.columns:
            if col.strip().lower() == 'disease':
                 disease_col_found = col
                 break

        if disease_col_found:
             print(f"\n{Fore.BLUE}üîπ Top 5 most frequent entries in '{disease_col_found}':")
             # Handle potential errors during value_counts
             try:
                 print(df[disease_col_found].value_counts().head(5))
             except Exception as e:
                  print(f"{Fore.YELLOW}   Could not get value counts: {e}")
        else:
            print(f"{Fore.YELLOW}   (Column 'disease' not found for frequency analysis)")

        print(f"{Fore.CYAN}{'='* (44 + len(description) + len(df_path.name))}")
        return True # Indicate success

    except Exception as e:
        print(f"{Fore.RED}‚ùå Error processing file {df_path.name}: {e}")
        print(f"{Fore.CYAN}{'='* (44 + len(description) + len(df_path.name))}")
        return False # Indicate failure


# --- Main Execution ---
if __name__ == "__main__":
    print(f"\n{Fore.MAGENTA}{'='*60}")
    print(f"{Fore.YELLOW}ü©∫ Data Preview ‚Äî Checking Key Project Data Files ü©∫")
    print(f"{Fore.MAGENTA}{'='*60}")

    # Preview the main training data file
    preview_dataframe(
        TRAINING_DATA_PATH,
        expected_cols={"disease", "training_text"}, # Check for lowercase columns now
        description="Training Data (Output of data_merger.py)"
    )

    # Preview the source file for the knowledge base
    # No specific column check, just show its structure
    preview_dataframe(
        KB_SOURCE_DATA_PATH,
        expected_cols=None, # We don't enforce specific columns other than 'Disease' conceptually
        description="Knowledge Base Source (Expected Wide Format)"
    )

    print(f"\n{Fore.GREEN}‚úÖ Data preview checks complete.")
    print(f"{Fore.MAGENTA}{'='*60}\n")